<h1>FlameNet: IECSE MIT Manipal Machine Learning Contest ðŸ”¥</h1>

<p>
This repository contains my solution for <strong>FlameNet</strong>, IECSEâ€™s exclusive 12-hour individual Machine Learning contest.
I took this opportunity to apply my machine learning, data analysis, and feature engineering skills on a challenging real-world dataset.
</p>

<h2>ðŸ“Œ About the Contest</h2>

<ul>
  <li><strong>Organized by:</strong> IECSE MIT Manipal</li>
  <li><strong>Platform:</strong> Kaggle</li>
  <li><strong>Duration:</strong> 29th June, 12:00 PM â€“ 30th June, 12:00 AM (IST)</li>
</ul>

<p>
<a href="https://www.kaggle.com/t/8d60ad6c73d472b8d42319b0ac2f56c0">View the competition on Kaggle</a>
</p>

<h2>Challenge Theme</h2>

<p>
My task was to predict <strong>quantum encryption performance</strong> under various simulated network and security conditions.
Each row in the dataset represented a specific system configuration and operational environment.
I built a multi-class classification model that predicted <code>Performance_Target</code> for unseen configurations.
</p>

<h2>Key Dataset Features</h2>

<ul>
  <li><code>Key_Size</code>: Encryption key length (bits)</li>
  <li><code>Protocol_Type</code>: Encryption protocol (e.g. BB84, E91)</li>
  <li><code>Key_Distribution</code>: Key distribution method (QKD, Hybrid QKD)</li>
  <li><code>Enc_Latency</code>, <code>Dec_Latency</code>, <code>Total_Latency</code>: Encryption/decryption/network delays</li>
  <li><code>Throughput</code>, <code>Packet_Loss</code>, <code>Bandwidth_Usage</code>, <code>RTT</code>: Network performance indicators</li>
  <li><code>Attack</code>, <code>Vulnerability</code>, <code>Attack_Success</code>, <code>IDS_Accuracy</code>: Security metrics</li>
  <li><code>Quantum_Entropy_Deviation</code>, <code>Photon_Count_Variability</code>: Quantum-level stability</li>
  <li><code>CPU_Usage</code>, <code>Memory_Usage</code>, <code>Energy_Consumption</code>: Resource usage</li>
  <li><code>Optimization</code>, <code>Latency_Throughput_Efficiency</code>, <code>Security_Exposure_Index</code>: Derived or strategy-related features</li>
</ul>

<h2>Rules and Guidelines</h2>

<ul>
  <li><strong>What I followed:</strong>
    <ul>
      <li>I analyzed and preprocessed only the provided dataset.</li>
      <li>I applied valid machine learning techniques and built a fully reproducible notebook.</li>
      <li>I ensured the notebook ran end-to-end without external dependencies or additional data.</li>
    </ul>
  </li>
  <li><strong>What I avoided:</strong>
    <ul>
      <li>I did not use external data for training.</li>
      <li>I did not use pre-trained models or external weights.</li>
      <li>I did not use large language models (e.g. ChatGPT, Gemini) for generating code or solutions.</li>
    </ul>
  </li>
</ul>

<h2>My Approach</h2>

<p>
During the contest, I:
</p>

<ul>
  <li>Conducted thorough exploratory data analysis (EDA) to understand patterns and correlations.</li>
  <li>Engineered meaningful features to improve model performance.</li>
  <li>Experimented with different models and tuned hyperparameters carefully.</li>
  <li>Focused on clean code and clear documentation to ensure full reproducibility.</li>
</ul>

<h2>Results</h2>

<p>
<strong>Results to be updated once declared.</strong>
</p>

<h2>Event Tags</h2>

<p>#FlameNet #EMBER2025 #MLMadness #MLBegins</p>

<h2>Final Note</h2>

<p>
I ensured that my submission was fair, competitive, and aligned with the competition guidelines.
This contest was a valuable learning experience in applying ML to complex quantum encryption scenarios.
</p>

